{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8j8Yb8DR6qg",
        "outputId": "aff942ae-b2dd-41d5-818e-6b3172a13647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/borhanitrash/animal-image-classification-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38.4M/38.4M [00:02<00:00, 18.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 3 classes.\n",
            "Using 2550 files for training.\n",
            "Found 3000 files belonging to 3 classes.\n",
            "Using 450 files for validation.\n",
            "Class names: ['cats', 'dogs', 'snakes']\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.3586 - loss: 1.1818 - val_accuracy: 0.3511 - val_loss: 1.1078\n",
            "Epoch 2/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.3704 - loss: 1.1017 - val_accuracy: 0.3956 - val_loss: 1.0856\n",
            "Epoch 3/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.3938 - loss: 1.0811 - val_accuracy: 0.4089 - val_loss: 1.0720\n",
            "Epoch 4/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.4013 - loss: 1.0716 - val_accuracy: 0.4422 - val_loss: 1.0580\n",
            "Epoch 5/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.4285 - loss: 1.0627 - val_accuracy: 0.4533 - val_loss: 1.0523\n",
            "Epoch 6/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.4341 - loss: 1.0531 - val_accuracy: 0.4511 - val_loss: 1.0463\n",
            "Epoch 7/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.4492 - loss: 1.0483 - val_accuracy: 0.4667 - val_loss: 1.0468\n",
            "Epoch 8/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.4640 - loss: 1.0436 - val_accuracy: 0.4622 - val_loss: 1.0384\n",
            "Epoch 9/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.4698 - loss: 1.0336 - val_accuracy: 0.4644 - val_loss: 1.0379\n",
            "Epoch 10/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4730 - loss: 1.0285 - val_accuracy: 0.4867 - val_loss: 1.0408\n",
            "Epoch 11/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.4833 - loss: 1.0248 - val_accuracy: 0.4644 - val_loss: 1.0386\n",
            "Epoch 12/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.4616 - loss: 1.0307 - val_accuracy: 0.4778 - val_loss: 1.0310\n",
            "Epoch 13/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.4627 - loss: 1.0242 - val_accuracy: 0.4822 - val_loss: 1.0304\n",
            "Epoch 14/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.4920 - loss: 1.0164 - val_accuracy: 0.4911 - val_loss: 1.0268\n",
            "Epoch 15/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.4853 - loss: 1.0120 - val_accuracy: 0.4956 - val_loss: 1.0293\n",
            "Epoch 16/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.4889 - loss: 1.0072 - val_accuracy: 0.4756 - val_loss: 1.0284\n",
            "Epoch 17/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - accuracy: 0.4936 - loss: 1.0097 - val_accuracy: 0.4978 - val_loss: 1.0265\n",
            "Epoch 18/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.4919 - loss: 0.9993 - val_accuracy: 0.4911 - val_loss: 1.0337\n",
            "Epoch 19/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.4924 - loss: 1.0001 - val_accuracy: 0.4933 - val_loss: 1.0238\n",
            "Epoch 20/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - accuracy: 0.4957 - loss: 1.0029 - val_accuracy: 0.5022 - val_loss: 1.0236\n",
            "Epoch 21/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.5043 - loss: 0.9980 - val_accuracy: 0.4844 - val_loss: 1.0243\n",
            "Epoch 22/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.5047 - loss: 0.9921 - val_accuracy: 0.4978 - val_loss: 1.0217\n",
            "Epoch 23/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5196 - loss: 0.9889 - val_accuracy: 0.4933 - val_loss: 1.0216\n",
            "Epoch 24/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.5174 - loss: 0.9865 - val_accuracy: 0.5244 - val_loss: 1.0194\n",
            "Epoch 25/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5095 - loss: 0.9851 - val_accuracy: 0.4978 - val_loss: 1.0216\n",
            "Epoch 26/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5176 - loss: 0.9829 - val_accuracy: 0.4867 - val_loss: 1.0213\n",
            "Epoch 27/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5237 - loss: 0.9785 - val_accuracy: 0.5111 - val_loss: 1.0177\n",
            "Epoch 28/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.4972 - loss: 0.9832 - val_accuracy: 0.4889 - val_loss: 1.0199\n",
            "Epoch 29/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.5116 - loss: 0.9834 - val_accuracy: 0.4867 - val_loss: 1.0277\n",
            "Epoch 30/30\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.5154 - loss: 0.9773 - val_accuracy: 0.4933 - val_loss: 1.0214\n",
            "Single Layer Perceptron Accuracy: 49.33\n",
            "Epoch 1/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 2s/step - accuracy: 0.3398 - loss: 1.7869 - val_accuracy: 0.4267 - val_loss: 1.0774\n",
            "Epoch 2/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.4354 - loss: 1.4406 - val_accuracy: 0.3956 - val_loss: 1.2973\n",
            "Epoch 3/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.5067 - loss: 1.2282 - val_accuracy: 0.4667 - val_loss: 1.1461\n",
            "Epoch 4/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.5454 - loss: 1.0997 - val_accuracy: 0.4933 - val_loss: 1.1195\n",
            "Epoch 5/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - accuracy: 0.5255 - loss: 1.1503 - val_accuracy: 0.5200 - val_loss: 1.1038\n",
            "Epoch 6/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.5723 - loss: 1.0337 - val_accuracy: 0.5156 - val_loss: 1.0952\n",
            "Epoch 7/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.5698 - loss: 1.0275 - val_accuracy: 0.5156 - val_loss: 1.0969\n",
            "Epoch 8/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.5963 - loss: 1.0197 - val_accuracy: 0.5244 - val_loss: 1.0810\n",
            "Epoch 9/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step - accuracy: 0.5912 - loss: 1.0090 - val_accuracy: 0.5244 - val_loss: 1.1169\n",
            "Epoch 10/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.5816 - loss: 0.9927 - val_accuracy: 0.4644 - val_loss: 1.2012\n",
            "Epoch 11/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.6015 - loss: 0.9141 - val_accuracy: 0.5400 - val_loss: 1.0351\n",
            "Epoch 12/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.6264 - loss: 0.9141 - val_accuracy: 0.5089 - val_loss: 1.1038\n",
            "Epoch 13/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6292 - loss: 0.8499 - val_accuracy: 0.5444 - val_loss: 1.0204\n",
            "Epoch 14/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.6238 - loss: 0.8751 - val_accuracy: 0.4933 - val_loss: 1.1555\n",
            "Epoch 15/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.6625 - loss: 0.8261 - val_accuracy: 0.5311 - val_loss: 1.0222\n",
            "Multilayer Perceptron Accuracy: 53.11\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step\n",
            "Single Layer Perceptron Accuracy: 0.32\n",
            "Multilayer Perceptron Accuracy: 0.32222222222222224\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"borhanitrash/animal-image-classification-dataset\")\n",
        "dataSetPath = path + \"/Animals\"\n",
        "\n",
        "# Image size & batch size\n",
        "imageSize = (256, 256)\n",
        "batchSize = 32\n",
        "\n",
        "# Load dataset with automatic labels\n",
        "dataSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataSetPath,\n",
        "    image_size = imageSize,\n",
        "    batch_size = batchSize,\n",
        "    validation_split = 0.15,  # Split into 80% training, 20% validation\n",
        "    subset=\"training\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataSetPath,\n",
        "    image_size=imageSize,\n",
        "    batch_size=batchSize,\n",
        "    validation_split=0.15,\n",
        "    subset=\"validation\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Class names (cats, dogs, snakes)\n",
        "classNames = dataSet.class_names\n",
        "numClasses = len(classNames)\n",
        "print(\"Class names:\", classNames)\n",
        "\n",
        "# Normalize the data (Scaling between 0 and 1)\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "dataSet = dataSet.map(lambda x, y: (normalization_layer(x), y))\n",
        "valSet = valSet.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "\n",
        "# Single Layer Perceptron\n",
        "SLPModel = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(256, 256, 3)),  # Flatten input\n",
        "    keras.layers.Dense(numClasses, activation='softmax')  # Output layer with softmax\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "SLPModel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "SLPModel.fit(dataSet, epochs=30, validation_data=valSet)\n",
        "\n",
        "_, accuracy_slp = SLPModel.evaluate(valSet, verbose=0)\n",
        "print('Single Layer Perceptron Accuracy: %.2f' % (accuracy_slp * 100))\n",
        "\n",
        "# Multilayer Perceptron\n",
        "MLPModel = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(256, 256, 3)),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(numClasses, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "MLPModel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "MLPModel.fit(dataSet, epochs=15, validation_data=valSet)\n",
        "\n",
        "_, accuracy_mlp = MLPModel.evaluate(valSet, verbose=0)\n",
        "print('Multilayer Perceptron Accuracy: %.2f' % (accuracy_mlp * 100))\n",
        "\n",
        "# Predictions\n",
        "slpPredictedY = np.argmax(SLPModel.predict(valSet), axis=-1)\n",
        "mlpPredictedY = np.argmax(MLPModel.predict(valSet), axis=-1)\n",
        "\n",
        "# Extract true labels from the validation dataset\n",
        "actualY = np.concatenate([y.numpy() for x, y in valSet], axis=0)\n",
        "\n",
        "# Calculate accuracy using scikit-learn\n",
        "accuracy_slp_sklearn = accuracy_score(actualY, slpPredictedY)\n",
        "accuracy_mlp_sklearn = accuracy_score(actualY, mlpPredictedY)\n",
        "\n",
        "print(\"Single Layer Perceptron Accuracy:\", accuracy_slp_sklearn)\n",
        "print(\"Multilayer Perceptron Accuracy:\", accuracy_mlp_sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "\n",
        "# Enable Eager Execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"borhanitrash/animal-image-classification-dataset\")\n",
        "dataSetPath = path + \"/Animals\"\n",
        "\n",
        "# Image size & batch size\n",
        "imageSize = (128, 128)  # Reduced size for efficiency\n",
        "batchSize = 32\n",
        "\n",
        "# Load dataset with automatic labels\n",
        "dataSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataSetPath,\n",
        "    image_size=imageSize,\n",
        "    batch_size=batchSize,\n",
        "    validation_split=0.15,\n",
        "    subset=\"training\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "valSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataSetPath,\n",
        "    image_size=imageSize,\n",
        "    batch_size=batchSize,\n",
        "    validation_split=0.15,\n",
        "    subset=\"validation\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Class names\n",
        "classNames = dataSet.class_names\n",
        "numClasses = len(classNames)\n",
        "print(\"Class names:\", classNames)\n",
        "\n",
        "# Data Augmentation\n",
        "dataAugmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "# Normalize data\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "dataSet = dataSet.map(lambda x, y: (dataAugmentation(normalization_layer(x)), y))\n",
        "valSet = valSet.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Ensure dataset is preloaded into memory\n",
        "dataSet = dataSet.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "valSet = valSet.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Single Layer Perceptron Model\n",
        "SLPModel = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(128, 128, 3)),\n",
        "    keras.layers.Dense(numClasses, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer_slp = keras.optimizers.Adam(learning_rate=0.001)\n",
        "SLPModel.compile(optimizer=optimizer_slp, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "SLPModel.fit(dataSet, epochs=20, validation_data=valSet)\n",
        "\n",
        "# Multilayer Perceptron Model\n",
        "MLPModel = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(128, 128, 3)),\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(numClasses, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer_mlp = keras.optimizers.Adam(learning_rate=0.001)\n",
        "MLPModel.compile(optimizer=optimizer_mlp, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "MLPModel.fit(dataSet, epochs=15, validation_data=valSet)\n",
        "\n",
        "# CNN Transfer Learning (MobileNetV2)\n",
        "baseModel = keras.applications.MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\n",
        "baseModel.trainable = False  # Freeze pre-trained layers\n",
        "\n",
        "CNNModel = keras.Sequential([\n",
        "    baseModel,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(numClasses, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer_cnn = keras.optimizers.Adam(learning_rate=0.001)\n",
        "CNNModel.compile(optimizer=optimizer_cnn, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "CNNModel.fit(dataSet, epochs=10, validation_data=valSet)\n",
        "\n",
        "# Evaluate Models\n",
        "_, accuracy_slp = SLPModel.evaluate(valSet, verbose=0)\n",
        "_, accuracy_mlp = MLPModel.evaluate(valSet, verbose=0)\n",
        "_, accuracy_cnn = CNNModel.evaluate(valSet, verbose=0)\n",
        "print(f'SLP Accuracy: {accuracy_slp:.2%}')\n",
        "print(f'MLP Accuracy: {accuracy_mlp:.2%}')\n",
        "print(f'CNN Accuracy: {accuracy_cnn:.2%}')\n",
        "\n",
        "# Predictions\n",
        "slpPredictedY = np.argmax(SLPModel.predict(valSet), axis=-1)\n",
        "mlpPredictedY = np.argmax(MLPModel.predict(valSet), axis=-1)\n",
        "cnnPredictedY = np.argmax(CNNModel.predict(valSet), axis=-1)\n",
        "\n",
        "# Extract true labels\n",
        "actualY = np.concatenate([y.numpy() for _, y in valSet], axis=0)\n",
        "\n",
        "# Accuracy using scikit-learn\n",
        "print(\"SLP Accuracy (sklearn):\", accuracy_score(actualY, slpPredictedY))\n",
        "print(\"MLP Accuracy (sklearn):\", accuracy_score(actualY, mlpPredictedY))\n",
        "print(\"CNN Accuracy (sklearn):\", accuracy_score(actualY, cnnPredictedY))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MSZBa4hiYJ0",
        "outputId": "3f201561-c3f3-40e0-9bf8-a457380ed73b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 3 classes.\n",
            "Using 2550 files for training.\n",
            "Found 3000 files belonging to 3 classes.\n",
            "Using 450 files for validation.\n",
            "Class names: ['cats', 'dogs', 'snakes']\n",
            "Epoch 1/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 189ms/step - accuracy: 0.3330 - loss: 6.1585 - val_accuracy: 0.3200 - val_loss: 4.7412\n",
            "Epoch 2/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 175ms/step - accuracy: 0.3674 - loss: 2.4427 - val_accuracy: 0.3578 - val_loss: 5.4292\n",
            "Epoch 3/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 182ms/step - accuracy: 0.3856 - loss: 3.8415 - val_accuracy: 0.3956 - val_loss: 2.8781\n",
            "Epoch 4/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 178ms/step - accuracy: 0.3865 - loss: 2.3004 - val_accuracy: 0.4133 - val_loss: 1.7615\n",
            "Epoch 5/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - accuracy: 0.4044 - loss: 2.2521 - val_accuracy: 0.3800 - val_loss: 2.3574\n",
            "Epoch 6/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 175ms/step - accuracy: 0.4029 - loss: 2.7276 - val_accuracy: 0.4178 - val_loss: 1.6272\n",
            "Epoch 7/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - accuracy: 0.4217 - loss: 1.6986 - val_accuracy: 0.3978 - val_loss: 1.9379\n",
            "Epoch 8/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 177ms/step - accuracy: 0.3933 - loss: 2.6553 - val_accuracy: 0.4400 - val_loss: 1.3693\n",
            "Epoch 9/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 179ms/step - accuracy: 0.4208 - loss: 1.9902 - val_accuracy: 0.3933 - val_loss: 2.7024\n",
            "Epoch 10/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - accuracy: 0.4410 - loss: 2.3655 - val_accuracy: 0.4533 - val_loss: 1.5955\n",
            "Epoch 11/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 177ms/step - accuracy: 0.4037 - loss: 1.9205 - val_accuracy: 0.4311 - val_loss: 2.4634\n",
            "Epoch 12/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 188ms/step - accuracy: 0.4079 - loss: 2.3947 - val_accuracy: 0.3200 - val_loss: 8.4799\n",
            "Epoch 13/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 176ms/step - accuracy: 0.3961 - loss: 3.2371 - val_accuracy: 0.4356 - val_loss: 1.7409\n",
            "Epoch 14/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 175ms/step - accuracy: 0.4149 - loss: 2.0557 - val_accuracy: 0.3511 - val_loss: 2.6395\n",
            "Epoch 15/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 185ms/step - accuracy: 0.4043 - loss: 2.1515 - val_accuracy: 0.4444 - val_loss: 1.4307\n",
            "Epoch 16/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 179ms/step - accuracy: 0.3936 - loss: 2.2645 - val_accuracy: 0.4044 - val_loss: 2.3955\n",
            "Epoch 17/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 177ms/step - accuracy: 0.3984 - loss: 3.1868 - val_accuracy: 0.3667 - val_loss: 3.7817\n",
            "Epoch 18/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 175ms/step - accuracy: 0.3936 - loss: 3.3207 - val_accuracy: 0.4533 - val_loss: 1.7283\n",
            "Epoch 19/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 174ms/step - accuracy: 0.4325 - loss: 2.0633 - val_accuracy: 0.4044 - val_loss: 1.7169\n",
            "Epoch 20/20\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 175ms/step - accuracy: 0.4051 - loss: 1.7831 - val_accuracy: 0.3578 - val_loss: 4.4926\n",
            "Epoch 1/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.4012 - loss: 1.4343 - val_accuracy: 0.3889 - val_loss: 2.8110\n",
            "Epoch 2/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.4283 - loss: 1.1940 - val_accuracy: 0.4933 - val_loss: 1.0255\n",
            "Epoch 3/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.4484 - loss: 1.1341 - val_accuracy: 0.4444 - val_loss: 1.1276\n",
            "Epoch 4/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.4873 - loss: 1.0645 - val_accuracy: 0.4689 - val_loss: 1.0983\n",
            "Epoch 5/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.4754 - loss: 1.0491 - val_accuracy: 0.5089 - val_loss: 1.0712\n",
            "Epoch 6/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.4837 - loss: 1.0536 - val_accuracy: 0.5267 - val_loss: 1.0807\n",
            "Epoch 7/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.5105 - loss: 1.0083 - val_accuracy: 0.4756 - val_loss: 1.0726\n",
            "Epoch 8/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.5233 - loss: 0.9821 - val_accuracy: 0.5200 - val_loss: 1.0518\n",
            "Epoch 9/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.5198 - loss: 0.9800 - val_accuracy: 0.5156 - val_loss: 0.9909\n",
            "Epoch 10/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.5246 - loss: 0.9803 - val_accuracy: 0.5489 - val_loss: 0.9832\n",
            "Epoch 11/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.5391 - loss: 0.9596 - val_accuracy: 0.5289 - val_loss: 0.9849\n",
            "Epoch 12/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.5292 - loss: 0.9722 - val_accuracy: 0.5378 - val_loss: 0.9548\n",
            "Epoch 13/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.5253 - loss: 0.9408 - val_accuracy: 0.4933 - val_loss: 0.9985\n",
            "Epoch 14/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.5368 - loss: 0.9370 - val_accuracy: 0.5156 - val_loss: 0.9562\n",
            "Epoch 15/15\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.5455 - loss: 0.9414 - val_accuracy: 0.5289 - val_loss: 0.9662\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.7983 - loss: 0.5293 - val_accuracy: 0.9644 - val_loss: 0.1218\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.9379 - loss: 0.1654 - val_accuracy: 0.9711 - val_loss: 0.1109\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - accuracy: 0.9359 - loss: 0.1641 - val_accuracy: 0.9622 - val_loss: 0.1161\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.9528 - loss: 0.1221 - val_accuracy: 0.9667 - val_loss: 0.1025\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.9536 - loss: 0.1229 - val_accuracy: 0.9644 - val_loss: 0.1151\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 2s/step - accuracy: 0.9570 - loss: 0.1147 - val_accuracy: 0.9667 - val_loss: 0.1287\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.9585 - loss: 0.0938 - val_accuracy: 0.9689 - val_loss: 0.1066\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.9736 - loss: 0.0757 - val_accuracy: 0.9667 - val_loss: 0.1155\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.9647 - loss: 0.0932 - val_accuracy: 0.9667 - val_loss: 0.1150\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.0781 - val_accuracy: 0.9644 - val_loss: 0.1302\n",
            "SLP Accuracy: 35.78%\n",
            "MLP Accuracy: 52.89%\n",
            "CNN Accuracy: 96.44%\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 673ms/step\n",
            "SLP Accuracy (sklearn): 0.32222222222222224\n",
            "MLP Accuracy (sklearn): 0.34\n",
            "CNN Accuracy (sklearn): 0.3422222222222222\n"
          ]
        }
      ]
    }
  ]
}